# -*- coding: utf-8 -*-
"""ML_Assignement_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BNp38DAKJm71DZfkUExNuO9PcqpXvyRn
"""

# ==========================================
# ML Assignment 2 - Model Training & Evaluation
# ==========================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import joblib

# Import Models
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

# Import Metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, roc_auc_score, precision_score,
    recall_score, f1_score, matthews_corrcoef, confusion_matrix
)
from sklearn.datasets import load_breast_cancer

# 1. Load Dataset (Breast Cancer Wisconsin)
# ------------------------------------------------
# 1. Load Dataset from CSV
# ==========================================
# REPLACE 'breast_cancer.csv' WITH YOUR ACTUAL FILE PATH
file_path = 'data.csv'  # <--- ENTER YOUR FILE PATH HERE
df = pd.read_csv(file_path)

print(f"Dataset Loaded from {file_path}")

# Preprocessing (Specific to Breast Cancer CSVs from Kaggle/UCI)
# ------------------------------------------------
# 1. Drop 'id' column if it exists (it's not useful for prediction)
if 'id' in df.columns:
    df = df.drop('id', axis=1)

# 2. Drop 'Unnamed: 32' (Common error in this specific CSV)
if 'Unnamed: 32' in df.columns:
    df = df.drop('Unnamed: 32', axis=1)

# 3. Define Features (X) and Target (y)
# The target column is usually named 'diagnosis' in the CSV version
# We must convert 'M' (Malignant) and 'B' (Benign) to numbers
X = df.drop('diagnosis', axis=1)
y = df['diagnosis'].map({'M': 0, 'B': 1}) # 0 = Malignant, 1 = Benign

print(f"Final Shape: {X.shape[0]} rows, {X.shape[1]} features")
# 2. Train-Test Split (80% Train, 20% Test)
# ------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Initialize Models
# ------------------------------------------------
models = {
    "Logistic Regression": LogisticRegression(max_iter=5000),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "kNN": KNeighborsClassifier(n_neighbors=5),
    "Naive Bayes": GaussianNB(),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
}

# 4. Train Models, Evaluate, and Save
# ------------------------------------------------
results = []
model_dir = "model"
if not os.path.exists(model_dir):
    os.makedirs(model_dir)

print("\nTraining models and calculating metrics...\n")

for name, model in models.items():
    # Train
    model.fit(X_train, y_train)

    # Predict
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for AUC

    # [cite_start]Calculate Metrics
    acc = accuracy_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_prob)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    mcc = matthews_corrcoef(y_test, y_pred)

    # Append to results list
    results.append({
        "ML Model Name": name,
        "Accuracy": round(acc, 4),
        "AUC": round(auc, 4),
        "Precision": round(prec, 4),
        "Recall": round(rec, 4),
        "F1 Score": round(f1, 4),
        "MCC": round(mcc, 4)
    })

    # [cite_start]Save the model (Required for Streamlit App Step)
    filename = os.path.join(model_dir, f"{name.replace(' ', '_').lower()}.pkl")
    joblib.dump(model, filename)
    print(f"Saved: {filename}")

# [cite_start]5. Display Comparison Table (Required for PDF)
# ------------------------------------------------
results_df = pd.DataFrame(results)
print("\n" + "="*50)
print("FINAL MODEL PERFORMANCE COMPARISON")
print("="*50)
print(results_df)

# Optional: Export results to CSV for your report
results_df.to_csv("model_performance.csv", index=False)

# Run this in Jupyter to create a proper test file for your App
test_df = X_test.copy()
test_df['target'] = y_test  # Add the answer key back in
test_df.to_csv("test_data.csv", index=False)
print("Updated 'test_data.csv' created. Download this for your app!")
